# FloydHub Introduction to Deep Learning

### Abstract

[Professor A. Ng has said that this is the new electricity](https://youtu.be/21EiKfQYZXc), [Google is switched from mobile-first to AI-first](https://youtu.be/Y2VF8tmLFHw?t=6m50s), someone  has compared it to magic, VCs, startups and media companies are riding the wave of hype, some people agree that AI is eating the world and other people are really scared due to sci-fi literature(such as Terminator, Matrix etc ...), [Zuck vs Elon declarations](https://www.theguardian.com/technology/2017/jul/25/elon-musk-mark-zuckerberg-artificial-intelligence-facebook-tesla) and human job replacement(taxi with autonomous car, [radiologist with precision medicine](https://youtu.be/2HMPRXstSvQ) and so on).
At FloydHub we firmly believe that this technology can change human-machine interaction providing additional value to our society, but if and only if this technology and their application will be widely understood and tested. One of the core value at FloydHub is to `#makeAIsimple` or `#spreadAIpower`. We want to build a new world providing to dreamers this technology in their toolbelt so that they can create, learn, and experiment *bringing what they have see in the future in our present*, `#bringFutureInPresent`. Shall we begin? ;)

Table of Contents:
	- [AI](#artificial-intelligence)
	- [ML](#machine-learning)
	- [DL](#deep-learning)
	- [Narrow AI](#narrow-ai)
	- [General AI](#general-ai)
	- [what's next?](#)
	- [Summary](#summary)

## Artificial Intelligence

Everyone are talking about the miracoulous effectivness of AI: AI can "see", AI can "understand" and AI can "whatsoever-a-people-can-do". Is this true? Well if you are riding the the wave of hype created around the last technology breakthrouts such as AlphaGo, you are feeding the hype beast if you use these words, but there are a lot of people who are extremly caurefull about the magic behind this technology. First of all we have to make sure to speak the same 'language' and to use the same semantic about the field we are discussing, so first question:

### What is AI?

According to Professor P. Norvig book: Artificial Intelligence a modern approach, we can define AI in 4 ways: Agent which thinks like a human, Agent which acts like a human, Agent which thinks rationally and Agent which acts rationally. Well, this can sound a bit weird but are we a rational species? It all depends from the definition of rational, but for simplicity we are assuming that rationality means: reasoning, even with emotions involved, about planning or taking decision so that the situation turns out to be good for the Agent.

So now, we have defined what is a AI, but what about Artificial Consciusness? The answer is simple: we have not a clue about what is consciusness, moreover we have not a shared definition about what is consciuousness. Someone point in the direction of self-awarness and some researcher think that once we will have fully translate all the brain functionalities, then the outcome of a model with this technology can be this "human" artifact.

What is raise from the previous definitions is that this field wants to create something that is similar to us but made from human hands.


### Why study AI?

Have you ever asked: How my brain works? Why can I do these thing? What's the difference from me to other animals? If you have asked this questions, do not feel you alone, otherwise: blissful carefreeness!

[Even if our behavior is the outcome of 1ms, 1s, 1h, 24h, 1 month, 1y, 100y, 1000y, 10...0y of evolution](https://youtu.be/NNnIGh9g6fA) what is the algorithm of intelligence behind us? If we replace the term human with agent: which is the algorithm that drive us in an environment where we can act and receive stimulus/observations to maximize future rewards according the goals defined by the algorithm? From the last question we can derive more questions: Are the goals hardcoded, continuosly changed or a mixed approach?

As in physic we have a lot of questions whose answers are unkwons, but as good scientists(you do not need a piece of paper to be certified as a scientist, is enough to have a lot of questions and a 'fire' which pushes us to never stop learning and find answers) driven by curiosity our duty is find answers: yes, even if from more answers come more questions; this is life mystery :).

Human specie is one of the most incredibly thing ever created in term of complexity and this is the main reason behind this incredible field. Solving the Intelligence mystery means unboxing human complexity and finally know ourselves in our fullyness.

### AI fields

![images AI multi-disciplinary]

AI is an extremely multi-disciplinary field, it covers: Planning, Robotics, Math, Neuroscience, Biology, Statistic, Natural Language Processing and Understanding, Knowledge Representation, Reasoning, and Machine Learning. Do not worry if you have not a solid understanding of these fields, during your journey, with us ;), you will learn a lot.

With the last achievement in this field, you can try to improve all the existing technologies and maybe simplify the human-machine interaction building a future where human possibilities will be so wide that the only limit is our immagination.

### Is AI an old field

Yes, even if we have not discussed the full history behind AI, it's good to know that the name AI was created by John McCarthy who spent all his life on it. But again we are not here to spend words on AI-story, we are here to understand what's behind this field and the recent breakthough. Before introducing the next building block we have to underline a thing.

### Knowledge Representation

![Knowledge representation image, rule engine inference]

The key component of reasoning, is to have someting to reasoning on! In the past, but even now, AI was/is reduced to hardcode structured informations in some computer representable format so that we can reason on it. With reason I mean: defining rules by which an algorithm can infer information from. Moreover we can explore the information represented using appropriate data structure such as graph or tree, and reduce the reasoning or planning task to a visit on this structures.

![translate a task to a visit on graph or tree]

It's easy to recognize that this is not the way we work in term of a possible knowledge pipeline. We acquire knowledge with experience: more the experiences we face more the knowledge we gain. In other terms: we learn knowledges, we have not any hardcoded knowledge. This bring us to the next building block.

## Machine Learning

Let me first introduce this subfield of AI with two popular definition:

1. A Machine/Computer-Programm which can perform task without being not explicit programmed;
2. A Machine/Computer-Programm is learning from Experience E, some class of Task T with Performance P, if its performance in T can be measure in P, improve with experience E.

### Trinity of Machine Learning

#### Supervised Learning
(student preparing for exam example: Train are assignments, Evaluation is exam)

#### Unsupervised Learning
the Yann LeCun cake: Twitter/Facebook post] [toddler in the world, he create useful representation of the world without any prior knownledge or label]

#### Reinforcement Learning
the Yann LeCun cake: Twitter/Facebook post] [toddler in the world, he learn interacting with the env.]

### ML workflow

#### Create a Dataset

#### Choose your Model

#### Train

#### Evaluate

### ML is an Optimization Problem


## Deep Learning

key concepts: NN rebranding, gpus(computational power) and representational learning

### What is a NN

### Everything goes deeper

Deep SL, Deep UL, DRL

### DL success

#### Mainstream reasons of adoption
![Andrew Ng NIPS tutorial 2016]

Transfer Learning
Representational Learning
More Data, More Accuracy



#### Real world applications

Self-driving car
precision medicine(rethinopathy and skin cancer detection)
Alpha Go
Conversational Agent
System reccomandation, Spam filter etc...


## Narrow AI

Current technology is capable to solve things without required a new way of interconnect knowledge like repetitive task and human task around 1-10s. Do one job at superhuman performance.


## General AI

No one knows how can we reach it.
The challenge:
 - Catastrophic forgetting (A new task delete the previous knowledge, how can we overcome this?)
 - Continuous Learning (in which way is organized the knowledge inside our brain?),
 - Safe AI (Are ML model, safe in term of cyber security(Adversarial example), but even not expected behavior? Example RL which exploit env.)
 - Unbiased Dataset (Machine and model are neither sexist nor racist, but their data can be, how can we unbiased ds?)

We need a Cognitive Toolkit to evaluate this model. (See Karpathy slide)

## What's next?

As just said above, the road to achieve GAI is not defined, even if we have not a well defined path, here a list of the most interesting topics which are pushing researcher to find a way to achieve GAI and may be a another step in the direction of the Intelligence Algorithm which drive our evolutionary behavior.

[Is Backpropagation the right algorithm to drive the learning process?](https://www.axios.com/ai-pioneer-advocates-starting-over-2485537027.html) This is a question of [Geoffry Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton) who recently become suspicious about the famous algo behind our learning models. I do not know if backprop is the right way to drive learning, but it's really notable and admirable when one of the man who have driven the research in this discipline has the courage to questioning their own work and try with a new formulation.

![slide 26 LeCun NIPS 2016 Predictive Learning]

[Unsupervised Learning is the cake](https://www.facebook.com/yann.lecun/posts/10153426023477143). Humans and animals do not learn from labeled data, this is main reason because unsupervised learning is so hot on Academia: researcher think that Unsupervised Learning is the key to learn good representation of data on which supervised and reinforcement learning will compute.

[AI = RL + DL](http://icml.cc/2016/tutorials/deep_rl_tutorial.pdf). This is a quote from [David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html), one of the main architech behind AlphaGo, Deep Reinforcement Learning is another very active research field where top AI companies are challeging each other(DeepMind, OpenAI etc...). Raising the bar in this field means having an Agent which is able to move into an enviroment and reaching is goals.

![Le Cun citation about GANs](https://cdn-images-1.medium.com/max/2000/1*AZ5-3WdNdYyC2U0Aq7RhIg.png)

[Generative Adversarial Network]() is the most interesting idea in the last ten years in machine learning. We have already discussed the amount of data needed to train our DL models. GANs is a really cool class of models whose purpose is to generate high quality data similar to the dataset distribution which they are learning. Since collecting dataset is extremely consuming in term of time and money resource, simulating/generating data is the only feasible solution. By instance: [Waymo is massively using simulation to train its automous systems](https://www.theatlantic.com/technology/archive/2017/08/inside-waymos-secret-testing-and-simulation-facilities/537648/), [Apple is using it to refine syntethic images](https://machinelearning.apple.com/2017/07/07/GAN.html), and other are pointing in the same direction. In order to train very deep model, you need a lot of high quality data.

[Prior Consciusness](https://arxiv.org/abs/1709.08568). Y. Bengio proposal of consciusness with our current knowledge and technolgy. [Follow this link for a great explanation.](https://www.quora.com/What-is-Yoshua-Bengios-new-Consciousness-Prior-paper-about)

[Opening the black box of deep neural networks via information](https://arxiv.org/abs/1703.00810). Prof. Shwartz-Ziv and Naftali Tishby have tried to explain what's happening during training. This research underline the following things:
- SGD involves 2 distinct phase: Memorization and Compression. Memorization phase: High Mean, Low Variance (few epochs), Compression phase: Low Mean, High Variance(a lot of epochs). This can be translate as: during the first step, the Information Plane of each Layer is adjust in a similar way to memorize the task, then each leayer begin to exclude all the irrelevant information(compression phase)
- the number of hidden layer reduces the training time to reach optimal compression and generalization
Follow this [link for a seminar on this work by Naftali Tishby](https://www.youtube.com/watch?v=FSfN2K3tnJU)

* There is a **hidden** chapter just below, can you find it?* (Gamification)

(hidden html element)
### What about AI apocalypse
Once we reach GAI it could be possible that can cause our extinctions?
Report image about who is supporting and who is not supporting
Elon vs Zuck
Siraj :)

## Summary

This was a high level introduction to the exciting field of Deep Learning (AI/ML/DL).
Our hope is that this article have inspired you as much as it has pushed us to build FloydHub and allow AI-folks and You to take our present in the future you have dreamed of.

